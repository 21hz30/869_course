{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Playground for Recommeder System slides\n",
    "\n",
    "- Stephen W. Thomas\n",
    "- Used for MMA 869, MMAI 869, and GMMA 869"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-08-13 14:26:12.194218\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "print(datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "INSTALLED VERSIONS\n",
      "------------------\n",
      "commit: None\n",
      "python: 3.6.4.final.0\n",
      "python-bits: 64\n",
      "OS: Windows\n",
      "OS-release: 10\n",
      "machine: AMD64\n",
      "processor: Intel64 Family 6 Model 142 Stepping 10, GenuineIntel\n",
      "byteorder: little\n",
      "LC_ALL: None\n",
      "LANG: None\n",
      "LOCALE: None.None\n",
      "\n",
      "pandas: 0.24.2\n",
      "pytest: 3.3.2\n",
      "pip: 19.0.3\n",
      "setuptools: 38.4.0\n",
      "Cython: 0.27.3\n",
      "numpy: 1.16.4\n",
      "scipy: 1.2.1\n",
      "pyarrow: None\n",
      "xarray: None\n",
      "IPython: 6.2.1\n",
      "sphinx: 1.6.6\n",
      "patsy: 0.5.0\n",
      "dateutil: 2.6.1\n",
      "pytz: 2017.3\n",
      "blosc: None\n",
      "bottleneck: 1.2.1\n",
      "tables: 3.4.2\n",
      "numexpr: 2.6.9\n",
      "feather: None\n",
      "matplotlib: 3.0.0\n",
      "openpyxl: 2.4.10\n",
      "xlrd: 1.1.0\n",
      "xlwt: 1.3.0\n",
      "xlsxwriter: 1.0.2\n",
      "lxml.etree: 4.3.4\n",
      "bs4: 4.6.0\n",
      "html5lib: 1.0.1\n",
      "sqlalchemy: 1.2.1\n",
      "pymysql: None\n",
      "psycopg2: None\n",
      "jinja2: 2.10\n",
      "s3fs: None\n",
      "fastparquet: None\n",
      "pandas_gbq: None\n",
      "pandas_datareader: None\n",
      "gcsfs: None\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.show_versions(as_json=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manual Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[ 3.,  3., nan,  4.,  5.,  0.],\n",
       "        [ 5.,  5.,  4., nan,  4.,  1.],\n",
       "        [ 4., nan,  5.,  3.,  4., nan],\n",
       "        [nan,  3., nan,  1., nan,  5.],\n",
       "        [ 0.,  4., nan,  2.,  4.,  4.],\n",
       "        [ 1.,  0.,  2.,  4.,  5.,  5.]])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(6, 6)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "U = np.matrix([\n",
    "    [3, 5, 4, np.nan, 0, 1], \n",
    "    [3, 5, np.nan, 3, 4, 0],\n",
    "    [np.nan, 4, 5, np.nan, np.nan, 2],\n",
    "    [4, np.nan, 3, 1, 2, 4],\n",
    "    [5, 4, 4, np.nan, 4, 5],\n",
    "    [0, 1, np.nan, 5, 4, 5]\n",
    "]).T\n",
    "U\n",
    "U.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[ 5.,  5.,  4., nan,  4.,  1.]])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0, cos_sim=0.932, cos_dist=0.068, euc_sim=0.240, euc_dist=3.162\n",
      "1, cos_sim=1.000, cos_dist=0.000, euc_sim=1.000, euc_dist=0.000\n",
      "2, cos_sim=0.982, cos_dist=0.018, euc_sim=0.414, euc_dist=1.414\n",
      "3, cos_sim=0.673, cos_dist=0.327, euc_sim=0.183, euc_dist=4.472\n",
      "4, cos_sim=0.705, cos_dist=0.295, euc_sim=0.145, euc_dist=5.916\n",
      "5, cos_sim=0.562, cos_dist=0.438, euc_sim=0.113, euc_dist=7.874\n"
     ]
    }
   ],
   "source": [
    "from scipy.spatial import distance\n",
    "\n",
    "u = U[1] # Mr Blue\n",
    "u\n",
    "\n",
    "for j in range(0, U.shape[1]):\n",
    "    v = U[j]\n",
    "    ind = np.isfinite(u) & np.isfinite(v)\n",
    "    if np.any(ind) == False:\n",
    "        cos_dist = 1\n",
    "        cos_sim  = 1 - cos_dist\n",
    "        euc_dist = 1000\n",
    "        euc_sim  = 1/(1+euc_dist)\n",
    "    else:\n",
    "        #print(u[ind])\n",
    "        #print(v[ind])\n",
    "        cos_dist = distance.cosine(u[ind], v[ind])\n",
    "        cos_sim  = 1 - cos_dist\n",
    "        euc_dist = distance.euclidean(u[ind], v[ind])\n",
    "        euc_sim  = 1/(1+euc_dist)\n",
    "    print(\"{}, cos_sim={:.3f}, cos_dist={:.3f}, euc_sim={:.3f}, euc_dist={:.3f}\".format(j, cos_sim, cos_dist, euc_sim, euc_dist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0, cos_sim=0.819, cos_dist=0.181, euc_sim=0.205, euc_dist=3.873\n",
      "1, cos_sim=0.648, cos_dist=0.352, euc_sim=0.167, euc_dist=5.000\n",
      "2, cos_sim=0.854, cos_dist=0.146, euc_sim=0.261, euc_dist=2.828\n",
      "3, cos_sim=1.000, cos_dist=0.000, euc_sim=1.000, euc_dist=0.000\n",
      "4, cos_sim=0.988, cos_dist=0.012, euc_sim=0.274, euc_dist=2.646\n",
      "5, cos_sim=0.668, cos_dist=0.332, euc_sim=0.141, euc_dist=6.083\n"
     ]
    }
   ],
   "source": [
    "u = U[:, 3] # LOTR\n",
    "\n",
    "for j in range(0, U.shape[0]):\n",
    "    v = U[:, j]\n",
    "    ind = np.isfinite(u) & np.isfinite(v)\n",
    "    if np.any(ind) == False:\n",
    "        cos_dist = 1\n",
    "        cos_sim  = 1 - cos_dist\n",
    "        euc_dist = 1000\n",
    "        euc_sim  = 1/(1+euc_dist)\n",
    "    else:\n",
    "        cos_dist = distance.cosine(u[ind], v[ind])\n",
    "        cos_sim  = 1 - cos_dist\n",
    "        euc_dist = distance.euclidean(u[ind], v[ind])\n",
    "        euc_sim  = 1/(1+euc_dist)\n",
    "    print(\"{}, cos_sim={:.3f}, cos_dist={:.3f}, euc_sim={:.3f}, euc_dist={:.3f}\".format(j, cos_sim, cos_dist, euc_sim, euc_dist))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jaccard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_similarity(l1, l2):\n",
    "    intersection = len(list(set(l1).intersection(l2)))\n",
    "    union = (len(l1) + len(l2)) - intersection\n",
    "    return float(intersection / union)\n",
    "\n",
    "list1 = ['dog', 'cat', 'fish']\n",
    "list2 = ['dog', 'cat', 'horse', 'pig']\n",
    "jaccard_similarity(list1, list2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Surprise Package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import SVD\n",
    "from surprise import Dataset\n",
    "from surprise import get_dataset_dir\n",
    "\n",
    "# Load the movielens-100k dataset (download it if needed).\n",
    "data = Dataset.load_builtin('ml-100k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io  # needed because of weird encoding of u.item file\n",
    "\n",
    "def read_item_names():\n",
    "    \"\"\"Read the u.item file from MovieLens 100-k dataset and return two\n",
    "    mappings to convert raw ids into movie names and movie names into raw ids.\n",
    "    \"\"\"\n",
    "\n",
    "    file_name = get_dataset_dir() + '/ml-100k/ml-100k/u.item'\n",
    "    rid_to_name = {}\n",
    "    name_to_rid = {}\n",
    "    with io.open(file_name, 'r', encoding='ISO-8859-1') as f:\n",
    "        for line in f:\n",
    "            line = line.split('|')\n",
    "            rid_to_name[line[0]] = line[1]\n",
    "            name_to_rid[line[1]] = line[0]\n",
    "\n",
    "    return rid_to_name, name_to_rid\n",
    "\n",
    "# Read the mappings raw id <-> movie name\n",
    "rid_to_name, name_to_rid = read_item_names()\n",
    "\n",
    "# Look at 10 random elements in the dict\n",
    "list(itertools.islice(name_to_rid.items(), 20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(data.raw_ratings)\n",
    "\n",
    "# Format is:\n",
    "# user item rating timestamp\n",
    "data.raw_ratings[0]\n",
    "data.raw_ratings[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data.raw_ratings, columns=['user', 'item', 'rating', 'timestamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_names = pd.DataFrame.from_dict(rid_to_name, orient=\"index\", columns=['item_name'])\n",
    "item_names['item'] = item_names.index\n",
    "item_names.head()\n",
    "df = pd.merge(df, item_names)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['user'] == '22']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build the Recommender System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import SVD\n",
    "from surprise import Dataset\n",
    "from surprise import accuracy\n",
    "from surprise.model_selection import train_test_split\n",
    "from surprise import KNNBaseline, KNNBasic, KNNWithMeans, KNNWithZScore, SVD\n",
    "\n",
    "trainset, testset = train_test_split(data, test_size=.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_options = {'name': 'MSD',\n",
    "               'user_based': True  # compute  similarities between items\n",
    "               }\n",
    "\n",
    "algo = KNNBasic(k=10, min_k=4, sim_options=sim_options)\n",
    "%time algo.fit(trainset)\n",
    "%time predictions = algo.test(testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy.rmse(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict for a specific user/item pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uid = str(196)  # raw user id (as in the ratings file). They are **strings**!\n",
    "iid = str(302)  # raw item id (as in the ratings file). They are **strings**!\n",
    "\n",
    "# get a prediction for specific users and items.\n",
    "pred = algo.predict(uid, iid, verbose=True)\n",
    "pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Top-Predicted Items for a Specific User"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def get_top_n(algo, predictions, n=10):\n",
    "    '''Return the top-N recommendation for each user from a set of predictions.\n",
    "\n",
    "    Args:\n",
    "        predictions(list of Prediction objects): The list of predictions, as\n",
    "            returned by the test method of an algorithm.\n",
    "        n(int): The number of recommendation to output for each user. Default\n",
    "            is 10.\n",
    "\n",
    "    Returns:\n",
    "    A dict where keys are user (raw) ids and values are lists of tuples:\n",
    "        [(raw item id, rating estimation), ...] of size n.\n",
    "    '''\n",
    "\n",
    "    # First map the predictions to each user.\n",
    "    top_n = defaultdict(list)\n",
    "    for uid, iid, true_r, est, _ in predictions:\n",
    "        #rid = algo.trainset.to_raw_iid(iid)\n",
    "        item_name = rid_to_name[iid]\n",
    "        #print('uid={}, iid={}, item_name={}, est={}'.format(uid, iid, item_name, est))\n",
    "        top_n[uid].append((iid, item_name, est))\n",
    "\n",
    "    # Then sort the predictions for each user and retrieve the k highest ones.\n",
    "    for uid, user_ratings in top_n.items():\n",
    "        user_ratings.sort(key=lambda x: x[2], reverse=True)\n",
    "        top_n[uid] = user_ratings[:n]\n",
    "\n",
    "    return top_n\n",
    "\n",
    "def get_user_neighbors(uid, k=10):\n",
    "    # Retrieve inner id of the movie\n",
    "    #raw_id = name_to_rid[item_name]\n",
    "    #inner_id = algo.trainset.to_inner_iid(raw_id)\n",
    "\n",
    "    # Retrieve inner ids of the nearest neighbors of the movie.\n",
    "    neighbors = algo.get_neighbors(uid, k=10)\n",
    "\n",
    "    # Convert inner ids of the neighbors into names.\n",
    "    #neighbors = (algo.trainset.to_raw_iid(inner_id) for inner_id in neighbors)\n",
    "    #neighbors = (rid_to_name[rid] for rid in neighbors)\n",
    "    return neighbors\n",
    "\n",
    "def user_info(uid, df, top_n, predictions):\n",
    "    print('Everything we know about User {}'.format(uid))\n",
    "    \n",
    "    df_user = df[df['user'] == uid]\n",
    "    print('Rating stats:')\n",
    "    print(df_user['rating'].value_counts(sort=False).sort_index())\n",
    "    \n",
    "    print('\\nTop 10 movies:')\n",
    "    print(df_user.sort_values(by=['rating'], ascending=False).head(5))\n",
    "    \n",
    "    print('\\nBottom 10 movies:')\n",
    "    print(df_user.sort_values(by=['rating'], ascending=True).head(5))\n",
    "    \n",
    "    print('\\nTop 10 predictions:')\n",
    "    for iid, item_name, rating in top_n[uid]:\n",
    "        print(\"{}, {}, {}\".format(iid, item_name, rating))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_n = get_top_n(algo, predictions, n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_info(str(653), df, top_n, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_info(str(2), df, top_n, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_info(str(8), df, top_n, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the recommended items for all users\n",
    "#for uid, user_ratings in top_n.items():\n",
    "    #print(uid, [iid for (iid, _) in user_ratings])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Nearest Neighbors of an Item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_item_neighbors(item_name, k=10):\n",
    "    # Retrieve inner id of the movie\n",
    "    raw_id = name_to_rid[item_name]\n",
    "    inner_id = algo.trainset.to_inner_iid(raw_id)\n",
    "\n",
    "    # Retrieve inner ids of the nearest neighbors of the movie.\n",
    "    neighbors = algo.get_neighbors(inner_id, k=10)\n",
    "\n",
    "    # Convert inner ids of the neighbors into names.\n",
    "    neighbors = (algo.trainset.to_raw_iid(inner_id) for inner_id in neighbors)\n",
    "    neighbors = (rid_to_name[rid] for rid in neighbors)\n",
    "    return neighbors\n",
    "\n",
    "item_name = 'Toy Story (1995)'\n",
    "print('The nearest neighbors of {} are:'.format(item_name))\n",
    "for movie in get_item_neighbors(item_name):\n",
    "    print(movie)\n",
    "    \n",
    "    \n",
    "item_name = 'Star Wars (1977)'\n",
    "print('\\nThe nearest neighbors of {} are:'.format(item_name))\n",
    "for movie in get_item_neighbors(item_name):\n",
    "    print(movie)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise.model_selection import cross_validate \n",
    "algo = SVD()\n",
    "\n",
    "# Run 5-fold cross-validation and print results.\n",
    "%time cross_validate(algo, data, measures=['RMSE', 'MAE'], cv=5, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time cross_validate(KNNBasic(), data, measures=['RMSE', 'MAE'], cv=5, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVD Algo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {'n_epochs': [5, 10], 'lr_all': [0.002, 0.005],\n",
    "              'reg_all': [0.4, 0.6]}\n",
    "gs = GridSearchCV(SVD, param_grid, measures=['rmse', 'mae'], cv=3)\n",
    "\n",
    "%time gs.fit(data)\n",
    "\n",
    "# best RMSE score\n",
    "print(gs.best_score['rmse'])\n",
    "\n",
    "# combination of parameters that gave the best RMSE score\n",
    "print(gs.best_params['rmse'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN Algo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_knn = {'k': [2, 10, 20],\n",
    "              'sim_options': {'name': ['msd', 'cosine'],\n",
    "                              'min_support': [1, 5, 20],\n",
    "                              'user_based': [False, True],\n",
    "                              'verbose': [False]}\n",
    "              }\n",
    "\n",
    "gs_knn = GridSearchCV(KNNBasic, param_grid_knn, measures=['rmse', 'mae'], cv=3)\n",
    "%time gs_knn.fit(data)\n",
    "print(gs_knn.best_score['rmse'])\n",
    "print(gs_knn.best_params['rmse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_knn.cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_knn = {'k': [2, 10, 20],\n",
    "              'sim_options': {'name': ['msd', 'cosine'],\n",
    "                              'min_support': [1, 5, 20],\n",
    "                              'user_based': [True],\n",
    "                              'verbose': [False]}\n",
    "              }\n",
    "\n",
    "\n",
    "gs_knn = GridSearchCV(KNNWithMeans, param_grid_knn, measures=['rmse', 'mae'], cv=3)\n",
    "%time gs_knn.fit(data)\n",
    "print(gs_knn.best_score['rmse'])\n",
    "print(gs_knn.best_params['rmse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
